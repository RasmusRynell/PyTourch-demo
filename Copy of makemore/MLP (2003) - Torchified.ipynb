{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f154637b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zyrie', 'zyron', 'zzyzx']\n",
      "32033\n"
     ]
    }
   ],
   "source": [
    "words = open('names.txt', 'r', encoding='utf-8').read().splitlines()\n",
    "print(words[-3:])\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "04a02682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters = sorted(list(set(''.join(words)))) # Get all individual letters sorted, should be alphabet (if all letters are once included in our names)\n",
    "num_of_unique_letters = len(letters) + 1 # Add 1 for '.' our special char\n",
    "stoi = {s:i+1 for i,s in enumerate(letters)} # Create a mapping from a char to a int in order to index in tensor\n",
    "stoi['.'] = 0 # Add . as a special char\n",
    "itos = {i:s for s,i in stoi.items()} # Create the mapping in reverse\n",
    "print(num_of_unique_letters)\n",
    "print(letters)\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "991ca757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zzyzx']\n",
      "([[0, 0, 0], [0, 0, 26], [0, 26, 26], [26, 26, 25], [26, 25, 26], [25, 26, 24]], [26, 26, 25, 26, 24, 0])\n"
     ]
    }
   ],
   "source": [
    "def build_data(words, nChars):\n",
    "    x, y = [], []\n",
    "    for w in words:\n",
    "        chs = list('.'*nChars + w + \".\")\n",
    "        chs = [stoi[c] for c in chs]\n",
    "        for i in range(len(chs)-nChars):\n",
    "            x.append(chs[i:i+nChars])\n",
    "            y.append(chs[i+nChars])\n",
    "    return (x,y)\n",
    "\n",
    "# Example 'zuzanna' becomes training example (.. -> z, ..z -> u, and so on until last nna -> .) and chars are converted to the ints\n",
    "\n",
    "nChars = 3\n",
    "print(words[-1:])\n",
    "print(build_data(words[-1:], nChars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79b158db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3070 Ti'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80648b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167940\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "\n",
    "random.shuffle(words)\n",
    "trainIdx = int(0.8*len(words))\n",
    "valIdx = int(0.9*len(words))\n",
    "\n",
    "xTrain, yTrain = build_data(words[0:trainIdx], nChars)\n",
    "xTrain = xTrain[0:3]\n",
    "ytrain = yTrain[0:3]\n",
    "xTrain = torch.tensor(xTrain)\n",
    "yTrain = torch.tensor(yTrain)\n",
    "\n",
    "xVal, yVal = build_data(words[trainIdx:valIdx], nChars)\n",
    "xVal = torch.tensor(xVal)\n",
    "yVal = torch.tensor(yVal)\n",
    "\n",
    "xTest, yTest = build_data(words[valIdx:], nChars)\n",
    "xTest = torch.tensor(xTest)\n",
    "yTest = torch.tensor(yTest)\n",
    "\n",
    "\n",
    "nC = 10 # Look up table, can also be seen as the first layer to our network\n",
    "nHiddenN = 200 # Size of hidden layer\n",
    "\n",
    "C = torch.randn((num_of_unique_letters, nC), generator=g)\n",
    "\n",
    "layers = [\n",
    "  torch.nn.Linear(num_of_unique_letters, nC, bias=False), torch.nn.BatchNorm1d(nHiddenN), torch.nn.Tanh(),\n",
    "  torch.nn.Linear(nHiddenN, nHiddenN, bias=False), torch.nn.BatchNorm1d(nHiddenN), torch.nn.Tanh(),\n",
    "  torch.nn.Linear(nHiddenN, nHiddenN, bias=False), torch.nn.BatchNorm1d(nHiddenN), torch.nn.Tanh(),\n",
    "  torch.nn.Linear(nHiddenN, nHiddenN, bias=False), torch.nn.BatchNorm1d(nHiddenN), torch.nn.Tanh(),\n",
    "  torch.nn.Linear(nHiddenN, nHiddenN, bias=False), torch.nn.BatchNorm1d(nHiddenN), torch.nn.Tanh(),\n",
    "  torch.nn.Linear(nHiddenN, num_of_unique_letters, bias=False)#, torch.nn.BatchNorm1d(num_of_unique_letters),\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "  for layer in layers[:-1]:\n",
    "    if isinstance(layer, torch.nn.Linear):\n",
    "      layer.weight *= 1.0 #5/3\n",
    "\n",
    "parameters = [C] + [p for layer in layers for p in layer.parameters()]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af0c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
